"""
Phase 2 Validation: Quantum-Inspired Enhancements

Comprehensive validation of Phase 2 quantum-inspired components:
1. MPS Attention mechanism
2. Quantum Fidelity Similarity metrics  
3. Multi-modal Tensor Fusion

Validates integration, performance, and compression targets.
"""

import torch
import numpy as np
import time
import logging
from typing import Dict, Any

# Phase 2 Components
from quantum_rerank.core.mps_attention import MPSAttention, MPSAttentionConfig, MPSTransformerLayer
from quantum_rerank.core.quantum_fidelity_similarity import (
    QuantumFidelitySimilarity, QuantumFidelityConfig, QuantumFidelityReranker
)
from quantum_rerank.core.multimodal_tensor_fusion import (
    MultiModalTensorFusion, MultiModalFusionConfig
)

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class Phase2Validator:
    """Comprehensive Phase 2 validation suite."""
    
    def __init__(self):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.batch_size = 4
        self.seq_len = 128
        self.embed_dim = 768
        self.num_docs = 10
        
        logger.info(f"Phase 2 Validator initialized on {self.device}")
    
    def validate_mps_attention(self) -> Dict[str, Any]:
        """Validate MPS attention implementation."""
        logger.info("=== Validating MPS Attention ===")
        
        try:
            # Test configuration
            config = MPSAttentionConfig(
                hidden_dim=self.embed_dim,
                num_heads=12,
                bond_dim=32,
                max_sequence_length=self.seq_len
            )
            
            # Initialize MPS attention
            mps_attention = MPSAttention(config).to(self.device)
            
            # Test data
            x = torch.randn(self.batch_size, self.seq_len, self.embed_dim).to(self.device)
            
            # Forward pass
            start_time = time.time()
            output, attention_weights = mps_attention(x, x, x, return_attention_weights=True)
            forward_time = time.time() - start_time
            
            # Validate output shape
            expected_shape = (self.batch_size, self.seq_len, self.embed_dim)
            assert output.shape == expected_shape, f"Expected {expected_shape}, got {output.shape}"
            
            # Get compression statistics
            compression_stats = mps_attention.get_compression_stats()
            
            # Test transformer layer
            transformer_layer = MPSTransformerLayer(config).to(self.device)
            layer_output = transformer_layer(x)
            assert layer_output.shape == expected_shape
            
            results = {
                "status": "PASSED",
                "forward_time_ms": forward_time * 1000,
                "output_shape": output.shape,
                "compression_ratio": compression_stats['compression_ratio'],
                "bond_dimension": compression_stats['bond_dimension'],
                "chain_length": compression_stats['chain_length'],
                "theoretical_complexity": compression_stats['theoretical_complexity'],
                "parameter_count": sum(p.numel() for p in mps_attention.parameters())
            }
            
            logger.info(f"âœ… MPS Attention: {compression_stats['compression_ratio']:.1f}x compression, "
                       f"{forward_time*1000:.2f}ms forward pass")
            
        except Exception as e:
            results = {"status": "FAILED", "error": str(e)}
            logger.error(f"âŒ MPS Attention validation failed: {e}")
        
        return results
    
    def validate_quantum_fidelity(self) -> Dict[str, Any]:
        """Validate quantum fidelity similarity implementation."""
        logger.info("=== Validating Quantum Fidelity Similarity ===")
        
        try:
            # Test configuration
            config = QuantumFidelityConfig(
                embed_dim=self.embed_dim,
                n_quantum_params=6,
                compression_ratio=32.0
            )
            
            # Initialize quantum fidelity similarity
            quantum_sim = QuantumFidelitySimilarity(config).to(self.device)
            
            # Test data
            query_emb = torch.randn(self.batch_size, self.embed_dim).to(self.device)
            doc_emb = torch.randn(self.batch_size, self.num_docs, self.embed_dim).to(self.device)
            
            # Test different similarity methods
            methods = ["quantum_fidelity", "classical_cosine", "hybrid"]
            method_results = {}
            
            for method in methods:
                start_time = time.time()
                similarity_result = quantum_sim(query_emb, doc_emb, method=method)
                method_time = time.time() - start_time
                
                similarity_scores = similarity_result["similarity"]
                expected_shape = (self.batch_size, self.num_docs)
                assert similarity_scores.shape == expected_shape, \
                    f"Expected {expected_shape}, got {similarity_scores.shape}"
                
                method_results[method] = {
                    "time_ms": method_time * 1000,
                    "score_range": (similarity_scores.min().detach().item(), similarity_scores.max().detach().item()),
                    "mean_score": similarity_scores.mean().detach().item()
                }
            
            # Test reranker
            reranker = QuantumFidelityReranker(config).to(self.device)
            single_query = query_emb[:1]
            candidates = doc_emb[0]  # First batch's documents
            
            rerank_results = reranker.rerank(
                single_query, candidates, top_k=5, method="quantum_fidelity"
            )
            
            # Get compression statistics
            compression_stats = quantum_sim.get_compression_stats()
            
            # Benchmark vs classical
            benchmark_results = reranker.benchmark_vs_classical(
                query_emb[:2], doc_emb[:2, :5], num_trials=10
            )
            
            results = {
                "status": "PASSED",
                "method_results": method_results,
                "compression_ratio": compression_stats["compression_ratio"],
                "classical_params": compression_stats["classical_parameters"],
                "quantum_params": compression_stats["quantum_parameters"],
                "rerank_time_ms": rerank_results["processing_time_ms"],
                "benchmark": benchmark_results,
                "parameter_count": sum(p.numel() for p in quantum_sim.parameters())
            }
            
            logger.info(f"âœ… Quantum Fidelity: {compression_stats['compression_ratio']:.1f}x compression, "
                       f"{method_results['quantum_fidelity']['time_ms']:.2f}ms similarity computation")
            
        except Exception as e:
            results = {"status": "FAILED", "error": str(e)}
            logger.error(f"âŒ Quantum Fidelity validation failed: {e}")
        
        return results
    
    def validate_multimodal_fusion(self) -> Dict[str, Any]:
        """Validate multi-modal tensor fusion implementation."""
        logger.info("=== Validating Multi-Modal Tensor Fusion ===")
        
        try:
            # Test configuration
            config = MultiModalFusionConfig(
                text_dim=768,
                image_dim=2048,
                tabular_dim=100,
                unified_dim=512,
                bond_dim=32
            )
            
            # Initialize fusion module
            fusion = MultiModalTensorFusion(config).to(self.device)
            
            # Test data for all modalities
            text_features = torch.randn(self.batch_size, 768).to(self.device)
            image_features = torch.randn(self.batch_size, 2048).to(self.device)
            tabular_features = torch.randn(self.batch_size, 100).to(self.device)
            
            # Test different fusion methods
            fusion_methods = ["tensor_product", "attention", "hybrid"]
            method_results = {}
            
            for method in fusion_methods:
                start_time = time.time()
                
                fusion_result = fusion(
                    text_features=text_features,
                    image_features=image_features,
                    tabular_features=tabular_features,
                    fusion_method=method
                )
                
                fusion_time = time.time() - start_time
                
                fused_features = fusion_result["fused_features"]
                expected_shape = (self.batch_size, config.unified_dim)
                assert fused_features.shape == expected_shape, \
                    f"Expected {expected_shape}, got {fused_features.shape}"
                
                coherence_value = fusion_result["coherence_measure"]
                coherence_item = coherence_value.item() if torch.is_tensor(coherence_value) else coherence_value
                
                method_results[method] = {
                    "time_ms": fusion_time * 1000,
                    "coherence_measure": coherence_item,
                    "active_modalities": fusion_result["active_modalities"],
                    "output_norm": torch.norm(fused_features, dim=-1).mean().item()
                }
            
            # Test partial modalities
            partial_results = {}
            partial_combinations = [
                ("text_only", {"text_features": text_features}),
                ("image_only", {"image_features": image_features}),
                ("text_image", {"text_features": text_features, "image_features": image_features})
            ]
            
            for combo_name, kwargs in partial_combinations:
                partial_result = fusion(**kwargs, fusion_method="tensor_product")
                partial_results[combo_name] = {
                    "output_shape": partial_result["fused_features"].shape,
                    "active_modalities": partial_result["active_modalities"]
                }
            
            # Get fusion statistics
            fusion_stats = fusion.get_fusion_stats()
            
            results = {
                "status": "PASSED",
                "method_results": method_results,
                "partial_modality_results": partial_results,
                "fusion_stats": fusion_stats,
                "parameter_count": sum(p.numel() for p in fusion.parameters()),
                "unified_dimension": config.unified_dim,
                "bond_dimension": config.bond_dim
            }
            
            logger.info(f"âœ… Multi-Modal Fusion: {fusion_stats['compression_ratio']:.1f}x compression, "
                       f"unified_dim={config.unified_dim}")
            
        except Exception as e:
            results = {"status": "FAILED", "error": str(e)}
            logger.error(f"âŒ Multi-Modal Fusion validation failed: {e}")
        
        return results
    
    def validate_integration(self) -> Dict[str, Any]:
        """Validate integration between Phase 2 components."""
        logger.info("=== Validating Phase 2 Integration ===")
        
        try:
            # Initialize all components
            attention_config = MPSAttentionConfig(hidden_dim=512, num_heads=8, bond_dim=32)  # Use 8 heads for 512 dim
            fidelity_config = QuantumFidelityConfig(embed_dim=512, n_quantum_params=6)
            fusion_config = MultiModalFusionConfig(unified_dim=512, bond_dim=32)
            
            mps_attention = MPSAttention(attention_config).to(self.device)
            quantum_fidelity = QuantumFidelitySimilarity(fidelity_config).to(self.device)
            multimodal_fusion = MultiModalTensorFusion(fusion_config).to(self.device)
            
            # Test integrated pipeline
            text_features = torch.randn(self.batch_size, 768).to(self.device)
            image_features = torch.randn(self.batch_size, 2048).to(self.device)
            
            start_time = time.time()
            
            # Step 1: Multi-modal fusion
            fusion_result = multimodal_fusion(
                text_features=text_features,
                image_features=image_features,
                fusion_method="hybrid"
            )
            fused_features = fusion_result["fused_features"]
            
            # Step 2: MPS attention processing
            # Add sequence dimension for attention
            fused_seq = fused_features.unsqueeze(1).expand(-1, 32, -1)
            attention_output, _ = mps_attention(fused_seq, fused_seq, fused_seq)
            
            # Step 3: Quantum fidelity similarity
            query_features = attention_output[:1].mean(dim=1)  # Average over sequence
            doc_features = attention_output[1:].mean(dim=1)
            
            similarity_result = quantum_fidelity(query_features, doc_features)
            similarities = similarity_result["similarity"]
            
            integration_time = time.time() - start_time
            
            # Validate pipeline output
            assert similarities.shape[0] == self.batch_size - 1, \
                f"Expected {self.batch_size - 1} similarities, got {similarities.shape[0]}"
            
            # Calculate total compression
            attention_compression = mps_attention.get_compression_stats()["compression_ratio"]
            fidelity_compression = quantum_fidelity.get_compression_stats()["compression_ratio"]
            fusion_compression = multimodal_fusion.get_fusion_stats()["compression_ratio"]
            
            total_compression = attention_compression * fidelity_compression * fusion_compression
            
            results = {
                "status": "PASSED",
                "integration_time_ms": integration_time * 1000,
                "pipeline_output_shape": similarities.shape,
                "component_compressions": {
                    "mps_attention": attention_compression,
                    "quantum_fidelity": fidelity_compression,
                    "multimodal_fusion": fusion_compression,
                    "total_compression": total_compression
                },
                "coherence_measure": fusion_result["coherence_measure"].item() if torch.is_tensor(fusion_result["coherence_measure"]) else fusion_result["coherence_measure"],
                "similarity_range": (similarities.min().detach().item(), similarities.max().detach().item())
            }
            
            logger.info(f"âœ… Phase 2 Integration: {total_compression:.1f}x total compression, "
                       f"{integration_time*1000:.2f}ms end-to-end")
            
        except Exception as e:
            results = {"status": "FAILED", "error": str(e)}
            logger.error(f"âŒ Phase 2 Integration validation failed: {e}")
        
        return results
    
    def run_full_validation(self) -> Dict[str, Any]:
        """Run complete Phase 2 validation suite."""
        logger.info("ğŸš€ Starting Phase 2 Validation Suite")
        
        validation_results = {
            "mps_attention": self.validate_mps_attention(),
            "quantum_fidelity": self.validate_quantum_fidelity(),
            "multimodal_fusion": self.validate_multimodal_fusion(),
            "integration": self.validate_integration()
        }
        
        # Summary
        passed_tests = sum(1 for result in validation_results.values() 
                          if result["status"] == "PASSED")
        total_tests = len(validation_results)
        
        logger.info(f"ğŸ“Š Phase 2 Validation Complete: {passed_tests}/{total_tests} tests passed")
        
        if passed_tests == total_tests:
            logger.info("ğŸ‰ All Phase 2 components validated successfully!")
        else:
            logger.warning("âš ï¸ Some Phase 2 components failed validation")
        
        validation_results["summary"] = {
            "passed_tests": passed_tests,
            "total_tests": total_tests,
            "success_rate": passed_tests / total_tests,
            "phase_2_status": "COMPLETED" if passed_tests == total_tests else "PARTIAL"
        }
        
        return validation_results


def main():
    """Run Phase 2 validation."""
    print("Phase 2 Validation: Quantum-Inspired Enhancements")
    print("=" * 60)
    
    validator = Phase2Validator()
    results = validator.run_full_validation()
    
    # Print summary
    summary = results["summary"]
    print(f"\nğŸ“Š VALIDATION SUMMARY")
    print(f"Tests Passed: {summary['passed_tests']}/{summary['total_tests']}")
    print(f"Success Rate: {summary['success_rate']:.1%}")
    print(f"Phase 2 Status: {summary['phase_2_status']}")
    
    # Print component details
    print(f"\nğŸ”§ COMPONENT DETAILS")
    for component, result in results.items():
        if component != "summary":
            status = "âœ… PASSED" if result["status"] == "PASSED" else "âŒ FAILED"
            print(f"{component.upper()}: {status}")
            if "compression_ratio" in result:
                print(f"  Compression: {result['compression_ratio']:.1f}x")
            if "parameter_count" in result:
                print(f"  Parameters: {result['parameter_count']:,}")
    
    if summary["phase_2_status"] == "COMPLETED":
        print(f"\nğŸ‰ Phase 2 quantum-inspired enhancements successfully implemented!")
        print(f"Ready for Phase 3: Production Optimization")
    
    return results


if __name__ == "__main__":
    main()